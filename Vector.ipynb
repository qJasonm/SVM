{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4f138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import pickle\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5647a70",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfd0cdc",
   "metadata": {},
   "source": [
    "## fill out the info below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e18eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "File_path_for_day_data = '/xxx/xxx/code/xxx/daylight image/train/day'\n",
    "File_path_for_night_data = '/xxx/xxx/code/xxx/daylight image/train/night'\n",
    "File_path_for_test_day_data = '/xxx/xxx/code/xxx/daylight image/test/day'\n",
    "File_path_for_test_night_data = '/xxx/xxx/code/xxx/daylight image/test/night'\n",
    "\n",
    "resize_pixel = 120 # 120x120\n",
    "\n",
    "# choose the way you want to modify the picture\n",
    "average_rgb = True\n",
    "grayscale = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b3968",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a17eea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(img_path):\n",
    "    folder_path = img_path \n",
    "    image_paths = []\n",
    "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.jpg\")))\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05ba56ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(img_paths,resize_pixel,average_rgb,grayscale):  # Replace with the path to your folder\n",
    "#     folder_path = img_path \n",
    "\n",
    "#     image_paths = []\n",
    "#     image_paths.extend(glob.glob(os.path.join(folder_path, \"*.jpg\")))\n",
    "\n",
    "    data = []\n",
    "    x = 0\n",
    "    print(len(img_paths))\n",
    "    \n",
    "    if grayscale == True:\n",
    "        for i in img_paths:\n",
    "\n",
    "            image = Image.open(i)\n",
    "            image = image.rotate(90)\n",
    "            new_size = (int(resize_pixel), int(resize_pixel))\n",
    "            image = image.resize((new_size))\n",
    "            pixel = image.load()\n",
    "            pic_data = []   \n",
    "            for colume in range(image.size[1]):\n",
    "                temp_data = []\n",
    "                for row in range(image.size[0]):\n",
    "                    temp_pix = list(pixel[colume,row])\n",
    "\n",
    "                    # Algorithm to turn picture to grayscale\n",
    "                    temp_averange = 0.299 * temp_pix[0] + 0.587 * temp_pix[1] + 0.114 * temp_pix[2]\n",
    "\n",
    "                    temp_data.append(temp_averange)\n",
    "                pic_data.append(temp_data)\n",
    "            data.append(pic_data)\n",
    "            x += 1\n",
    "            \n",
    "    elif average_rgb == True:\n",
    "        for i in img_paths:\n",
    "\n",
    "            image = Image.open(i)\n",
    "            image = image.rotate(90)\n",
    "            image = image.resize((resize_pixel,resize_pixel))\n",
    "            pixel = image.load()\n",
    "            pic_data = []   \n",
    "            for colume in range(image.size[0]):\n",
    "                temp_data = []\n",
    "                for row in range(image.size[1]):\n",
    "                    temp_pix = list(pixel[colume,row])\n",
    "\n",
    "                    # Algorithm to turn picture to average rgb\n",
    "                    temp_averange = sum(temp_pix)/3\n",
    "\n",
    "                    temp_data.append(temp_averange)\n",
    "                pic_data.append(temp_data)\n",
    "            data.append(pic_data)\n",
    "            x += 1\n",
    "            \n",
    "    data = np.array(data).reshape((x,int(resize_pixel**2)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79491efe",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35faa594",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_data = get_data(File_path_for_day_data)\n",
    "night_data = get_data(File_path_for_night_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54378a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['file'] = day_data\n",
    "df['mark'] = 1\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a864f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['file'] = night_data\n",
    "df1['mark'] = -1\n",
    "df1 = df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeaa5a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([df,df1])\n",
    "train_data =train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d3fe046",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.sample(frac=1)\n",
    "train_data =train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fdd3f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "x = data_clean(train_data['file'],resize_pixel,average_rgb,grayscale)\n",
    "Y = train_data['mark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbc6a937",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreshape((resize_pixel, resize_pixel))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create a grayscale image using matplotlib\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(data, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "data = x[0].reshape((resize_pixel, resize_pixel))\n",
    "\n",
    "# Create a grayscale image using matplotlib\n",
    "plt.imshow(data, cmap='bone')\n",
    "plt.axis('off')  # Turn off the axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e1d2ce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f01dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28906668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supportvectormachine(x, Y, learning_Rate, epochs):\n",
    "#     archive = []\n",
    "    x =  np.append(x, np.array([np.ones(len(x))]).T, axis=1)\n",
    "    weights = np.random.rand(len(x.T)) # One weight for each column of the feature set. (Another way to say it is a weight for each feature.)\n",
    "    \n",
    "    # Loop over all the data\n",
    "    for i in tqdm(range(epochs)):\n",
    "        \n",
    "#         # Create an arcive so that we can plot many different SVM lines.\n",
    "#         archive.append([i,weights[0], weights[1]])\n",
    "         \n",
    "        # Predict over all the x feature training data.\n",
    "        y_pred = np.dot(x, weights)\n",
    "        \n",
    "        # Get the value of the true answer times the predicted value. (This is y * <x,w> above)\n",
    "        value = Y * y_pred\n",
    "        \n",
    "        # Set a location. Since we will be working through all the data one at a time, this will keep our position.\n",
    "        location = 0\n",
    "        \n",
    "        # Loop over all the data in the training set. Note in this loop t is set to an element of the array, value.\n",
    "        for t in value:\n",
    "            \n",
    "            # The above sudogradient requires us to check the sign of one part of the gradient. So this gate will do that for us. \n",
    "            \n",
    "            # Correct guess weight update.\n",
    "            if t > 0:\n",
    "                weights = weights  # - learning_Rate * (2 * 1 / epochs * weights )\n",
    "            \n",
    "            # Incorrect guess weight update.\n",
    "            else:\n",
    "                weights  = weights + learning_Rate * ( Y[location] * x[location] ) # - 2 * 1 / epochs * weights)\n",
    "                \n",
    "            \n",
    "            # Move one location in the data set (we will need to do this for each epoch)\n",
    "            location += 1\n",
    "    \n",
    "    # Return the weights, the list of intercepts and the list of slopes.\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d4c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57860f5d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9006d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = File_path_for_test_day_data\n",
    "image_paths = []\n",
    "image_paths.extend(glob.glob(os.path.join(folder_path, \"*.jpg\")))\n",
    "df2 = pd.DataFrame()\n",
    "df2['file'] = image_paths\n",
    "df2['mark'] = 1\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eb82ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = File_path_for_test_night_data\n",
    "image_paths = []\n",
    "image_paths.extend(glob.glob(os.path.join(folder_path, \"*.jpg\")))\n",
    "df3 = pd.DataFrame()\n",
    "df3['file'] = image_paths\n",
    "df3['mark'] = -1\n",
    "df3 = df3.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e0c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([df2,df3])\n",
    "test_data =test_data.reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1)\n",
    "test_x = data_clean(test_data['file'],resize_pixel,average_rgb,grayscale)\n",
    "test_y = test_data['mark']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2a408e",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591aff3",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    w = supportvectormachine(x, Y, 0.0001, 100000)\n",
    "\n",
    "    V = [] # Empty list to collect the predictions.\n",
    "\n",
    "    test_x = test_x # Assign the testing data.\n",
    "    test_y = np.array(test_data['mark']) # Assign the testing targets.\n",
    "\n",
    "    # Loop over all the testing features to get the classification probabilities.\n",
    "    for i in range(len(test_x)):\n",
    "        V.append(np.dot(w[:-1], test_x[i]) + w[-1])\n",
    "\n",
    "    new_y_pred = [] # Empty list for the predictions.\n",
    "\n",
    "    # If the predicetion value is greater then 1, give it a value of 1 and if it is less than on give it a value of -1.\n",
    "    for val in V:\n",
    "        if(val > 0):\n",
    "            new_y_pred.append(1)\n",
    "        else:\n",
    "            new_y_pred.append(-1)    \n",
    "            \n",
    "    print(\"Total number correct: \", accuracy_score(test_y,new_y_pred, normalize = False))\n",
    "    print(\"Total number in the testing data: \", len(test_data['mark']))\n",
    "    accuracy =  accuracy_score(test_y,new_y_pred, normalize = False)/len(test_data['mark'])\n",
    "    print(\"score:\",accuracy )\n",
    "        \n",
    "    if accuracy > 0.94:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3233e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"my_list_average_480.pkl\"\n",
    "# with open(file_path,'wb') as file:\n",
    "#     pickle.dump(w, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5315cbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9028b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
